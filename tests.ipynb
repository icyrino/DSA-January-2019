{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data\\dataset_treino.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_gestacoes</th>\n",
       "      <th>glicose</th>\n",
       "      <th>pressao_sanguinea</th>\n",
       "      <th>grossura_pele</th>\n",
       "      <th>insulina</th>\n",
       "      <th>bmi</th>\n",
       "      <th>indice_historico</th>\n",
       "      <th>idade</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  num_gestacoes  glicose  pressao_sanguinea  grossura_pele  insulina  \\\n",
       "0   1              6      148                 72             35         0   \n",
       "1   2              1       85                 66             29         0   \n",
       "2   3              8      183                 64              0         0   \n",
       "3   4              1       89                 66             23        94   \n",
       "4   5              0      137                 40             35       168   \n",
       "\n",
       "    bmi  indice_historico  idade  classe  \n",
       "0  33.6             0.627     50       1  \n",
       "1  26.6             0.351     31       0  \n",
       "2  23.3             0.672     32       1  \n",
       "3  28.1             0.167     21       0  \n",
       "4  43.1             2.288     33       1  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    392\n",
       "1    208\n",
       "Name: classe, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['classe'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_gestacoes</th>\n",
       "      <th>glicose</th>\n",
       "      <th>pressao_sanguinea</th>\n",
       "      <th>grossura_pele</th>\n",
       "      <th>insulina</th>\n",
       "      <th>bmi</th>\n",
       "      <th>indice_historico</th>\n",
       "      <th>idade</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>300.500000</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>120.135000</td>\n",
       "      <td>68.681667</td>\n",
       "      <td>20.558333</td>\n",
       "      <td>79.528333</td>\n",
       "      <td>31.905333</td>\n",
       "      <td>0.481063</td>\n",
       "      <td>33.278333</td>\n",
       "      <td>0.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>173.349358</td>\n",
       "      <td>3.362009</td>\n",
       "      <td>32.658246</td>\n",
       "      <td>19.360226</td>\n",
       "      <td>16.004588</td>\n",
       "      <td>116.490583</td>\n",
       "      <td>8.009638</td>\n",
       "      <td>0.337284</td>\n",
       "      <td>11.822315</td>\n",
       "      <td>0.476306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>150.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.075000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>300.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>450.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>122.750000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>600.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  num_gestacoes     glicose  pressao_sanguinea  \\\n",
       "count  600.000000     600.000000  600.000000         600.000000   \n",
       "mean   300.500000       3.820000  120.135000          68.681667   \n",
       "std    173.349358       3.362009   32.658246          19.360226   \n",
       "min      1.000000       0.000000    0.000000           0.000000   \n",
       "25%    150.750000       1.000000   99.000000          64.000000   \n",
       "50%    300.500000       3.000000  116.000000          70.000000   \n",
       "75%    450.250000       6.000000  140.000000          80.000000   \n",
       "max    600.000000      17.000000  198.000000         122.000000   \n",
       "\n",
       "       grossura_pele    insulina         bmi  indice_historico       idade  \\\n",
       "count     600.000000  600.000000  600.000000        600.000000  600.000000   \n",
       "mean       20.558333   79.528333   31.905333          0.481063   33.278333   \n",
       "std        16.004588  116.490583    8.009638          0.337284   11.822315   \n",
       "min         0.000000    0.000000    0.000000          0.078000   21.000000   \n",
       "25%         0.000000    0.000000   27.075000          0.248000   24.000000   \n",
       "50%        23.000000   36.500000   32.000000          0.384000   29.000000   \n",
       "75%        32.000000  122.750000   36.525000          0.647000   40.000000   \n",
       "max        99.000000  846.000000   67.100000          2.420000   81.000000   \n",
       "\n",
       "           classe  \n",
       "count  600.000000  \n",
       "mean     0.346667  \n",
       "std      0.476306  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['glicose'] = df['glicose'].replace(to_replace = 0, value = df['glicose'].median())\n",
    "df['pressao_sanguinea'] = df['pressao_sanguinea'].replace(to_replace = 0, value = df['pressao_sanguinea'].median())\n",
    "df['grossura_pele'] = df['grossura_pele'].replace(to_replace = 0, value = df['grossura_pele'].median())\n",
    "df['insulina'] = df['insulina'].replace(to_replace = 0, value = df['insulina'].median())\n",
    "df['bmi'] = df['bmi'].replace(to_replace = 0, value = df['bmi'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['id', 'classe'], axis=1)\n",
    "y = df['classe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y, test_size = .3, random_state = 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ytrain == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ytrain == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = sm.fit_sample(xtrain, ytrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ytrain == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ytrain == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6722222222222223"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1024)              9216      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 534,529\n",
      "Trainable params: 534,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 546 samples, validate on 180 samples\n",
      "Epoch 1/92\n",
      "546/546 [==============================] - 81s 149ms/step - loss: 0.6858 - acc: 0.6245 - val_loss: 0.6509 - val_acc: 0.6167\n",
      "Epoch 2/92\n",
      "546/546 [==============================] - 82s 149ms/step - loss: 0.6102 - acc: 0.7875 - val_loss: 0.6244 - val_acc: 0.6278\n",
      "Epoch 3/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.5571 - acc: 0.7839 - val_loss: 0.6075 - val_acc: 0.6500\n",
      "Epoch 4/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.5183 - acc: 0.7692 - val_loss: 0.5945 - val_acc: 0.6667\n",
      "Epoch 5/92\n",
      "546/546 [==============================] - 78s 144ms/step - loss: 0.4899 - acc: 0.7784 - val_loss: 0.5836 - val_acc: 0.6889\n",
      "Epoch 6/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.4700 - acc: 0.7784 - val_loss: 0.5765 - val_acc: 0.6944\n",
      "Epoch 7/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.4570 - acc: 0.7821 - val_loss: 0.5747 - val_acc: 0.7111\n",
      "Epoch 8/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.4485 - acc: 0.7802 - val_loss: 0.5780 - val_acc: 0.7111\n",
      "Epoch 9/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.4415 - acc: 0.7875 - val_loss: 0.5850 - val_acc: 0.7056\n",
      "Epoch 10/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.4348 - acc: 0.7912 - val_loss: 0.5944 - val_acc: 0.6944\n",
      "Epoch 11/92\n",
      "546/546 [==============================] - 79s 146ms/step - loss: 0.4284 - acc: 0.7912 - val_loss: 0.6037 - val_acc: 0.6889\n",
      "Epoch 12/92\n",
      "546/546 [==============================] - 84s 154ms/step - loss: 0.4231 - acc: 0.8004 - val_loss: 0.6102 - val_acc: 0.6944\n",
      "Epoch 13/92\n",
      "546/546 [==============================] - 80s 146ms/step - loss: 0.4187 - acc: 0.7949 - val_loss: 0.6119 - val_acc: 0.6833\n",
      "Epoch 14/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.4147 - acc: 0.8077 - val_loss: 0.6089 - val_acc: 0.6722\n",
      "Epoch 15/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.4102 - acc: 0.8095 - val_loss: 0.6031 - val_acc: 0.6722\n",
      "Epoch 16/92\n",
      "546/546 [==============================] - 78s 143ms/step - loss: 0.4050 - acc: 0.8114 - val_loss: 0.5971 - val_acc: 0.6778\n",
      "Epoch 17/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.3992 - acc: 0.8168 - val_loss: 0.5930 - val_acc: 0.6722\n",
      "Epoch 18/92\n",
      "546/546 [==============================] - 80s 146ms/step - loss: 0.3929 - acc: 0.8187 - val_loss: 0.5917 - val_acc: 0.6722\n",
      "Epoch 19/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.3866 - acc: 0.8260 - val_loss: 0.5929 - val_acc: 0.6722\n",
      "Epoch 20/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.3807 - acc: 0.8242 - val_loss: 0.5955 - val_acc: 0.6722\n",
      "Epoch 21/92\n",
      "546/546 [==============================] - 78s 144ms/step - loss: 0.3755 - acc: 0.8260 - val_loss: 0.5982 - val_acc: 0.6889\n",
      "Epoch 22/92\n",
      "546/546 [==============================] - 78s 144ms/step - loss: 0.3708 - acc: 0.8315 - val_loss: 0.5998 - val_acc: 0.6833\n",
      "Epoch 23/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.3662 - acc: 0.8370 - val_loss: 0.5999 - val_acc: 0.6833\n",
      "Epoch 24/92\n",
      "546/546 [==============================] - 81s 147ms/step - loss: 0.3615 - acc: 0.8480 - val_loss: 0.5993 - val_acc: 0.6778\n",
      "Epoch 25/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.3567 - acc: 0.8462 - val_loss: 0.5992 - val_acc: 0.6889\n",
      "Epoch 26/92\n",
      "546/546 [==============================] - 78s 143ms/step - loss: 0.3518 - acc: 0.8480 - val_loss: 0.6003 - val_acc: 0.6778\n",
      "Epoch 27/92\n",
      "546/546 [==============================] - 78s 143ms/step - loss: 0.3469 - acc: 0.8553 - val_loss: 0.6031 - val_acc: 0.6778\n",
      "Epoch 28/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.3421 - acc: 0.8571 - val_loss: 0.6067 - val_acc: 0.6722\n",
      "Epoch 29/92\n",
      "546/546 [==============================] - 80s 147ms/step - loss: 0.3374 - acc: 0.8553 - val_loss: 0.6105 - val_acc: 0.6778\n",
      "Epoch 30/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.3327 - acc: 0.8590 - val_loss: 0.6139 - val_acc: 0.6778\n",
      "Epoch 31/92\n",
      "546/546 [==============================] - 81s 148ms/step - loss: 0.3277 - acc: 0.8590 - val_loss: 0.6180 - val_acc: 0.6889\n",
      "Epoch 32/92\n",
      "546/546 [==============================] - 81s 149ms/step - loss: 0.3226 - acc: 0.8608 - val_loss: 0.6239 - val_acc: 0.6889\n",
      "Epoch 33/92\n",
      "546/546 [==============================] - 79s 146ms/step - loss: 0.3175 - acc: 0.8663 - val_loss: 0.6320 - val_acc: 0.6889\n",
      "Epoch 34/92\n",
      "546/546 [==============================] - 81s 147ms/step - loss: 0.3124 - acc: 0.8681 - val_loss: 0.6409 - val_acc: 0.6944\n",
      "Epoch 35/92\n",
      "546/546 [==============================] - 81s 148ms/step - loss: 0.3074 - acc: 0.8645 - val_loss: 0.6487 - val_acc: 0.6944\n",
      "Epoch 36/92\n",
      "546/546 [==============================] - 78s 143ms/step - loss: 0.3024 - acc: 0.8736 - val_loss: 0.6546 - val_acc: 0.6944\n",
      "Epoch 37/92\n",
      "546/546 [==============================] - 78s 143ms/step - loss: 0.2971 - acc: 0.8773 - val_loss: 0.6595 - val_acc: 0.6944\n",
      "Epoch 38/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.2919 - acc: 0.8755 - val_loss: 0.6647 - val_acc: 0.6889\n",
      "Epoch 39/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.2866 - acc: 0.8773 - val_loss: 0.6708 - val_acc: 0.6944\n",
      "Epoch 40/92\n",
      "546/546 [==============================] - 78s 144ms/step - loss: 0.2814 - acc: 0.8791 - val_loss: 0.6776 - val_acc: 0.6944\n",
      "Epoch 41/92\n",
      "546/546 [==============================] - 78s 144ms/step - loss: 0.2762 - acc: 0.8883 - val_loss: 0.6842 - val_acc: 0.6944\n",
      "Epoch 42/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.2710 - acc: 0.8883 - val_loss: 0.6908 - val_acc: 0.6944\n",
      "Epoch 43/92\n",
      "546/546 [==============================] - 78s 143ms/step - loss: 0.2657 - acc: 0.8901 - val_loss: 0.6984 - val_acc: 0.6944\n",
      "Epoch 44/92\n",
      "546/546 [==============================] - 78s 143ms/step - loss: 0.2605 - acc: 0.8901 - val_loss: 0.7070 - val_acc: 0.7000\n",
      "Epoch 45/92\n",
      "546/546 [==============================] - 82s 150ms/step - loss: 0.2553 - acc: 0.8938 - val_loss: 0.7153 - val_acc: 0.7000\n",
      "Epoch 46/92\n",
      "546/546 [==============================] - 78s 144ms/step - loss: 0.2501 - acc: 0.8974 - val_loss: 0.7225 - val_acc: 0.7167\n",
      "Epoch 47/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.2448 - acc: 0.9011 - val_loss: 0.7295 - val_acc: 0.7222\n",
      "Epoch 48/92\n",
      "546/546 [==============================] - 80s 146ms/step - loss: 0.2394 - acc: 0.9048 - val_loss: 0.7379 - val_acc: 0.7167\n",
      "Epoch 49/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.2341 - acc: 0.9066 - val_loss: 0.7479 - val_acc: 0.7167\n",
      "Epoch 50/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.2287 - acc: 0.9084 - val_loss: 0.7581 - val_acc: 0.7222\n",
      "Epoch 51/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.2233 - acc: 0.9084 - val_loss: 0.7677 - val_acc: 0.7167\n",
      "Epoch 52/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.2179 - acc: 0.9121 - val_loss: 0.7772 - val_acc: 0.7167\n",
      "Epoch 53/92\n",
      "546/546 [==============================] - 79s 144ms/step - loss: 0.2125 - acc: 0.9139 - val_loss: 0.7869 - val_acc: 0.7167\n",
      "Epoch 54/92\n",
      "546/546 [==============================] - 79s 145ms/step - loss: 0.2071 - acc: 0.9139 - val_loss: 0.7954 - val_acc: 0.7167\n",
      "Epoch 55/92\n",
      "546/546 [==============================] - 80s 146ms/step - loss: 0.2017 - acc: 0.9176 - val_loss: 0.8035 - val_acc: 0.7167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/92\n",
      "546/546 [==============================] - 81s 149ms/step - loss: 0.1962 - acc: 0.9194 - val_loss: 0.8135 - val_acc: 0.7111\n",
      "Epoch 57/92\n",
      "546/546 [==============================] - 81s 148ms/step - loss: 0.1908 - acc: 0.9267 - val_loss: 0.8247 - val_acc: 0.7111\n",
      "Epoch 58/92\n",
      "546/546 [==============================] - 81s 148ms/step - loss: 0.1853 - acc: 0.9322 - val_loss: 0.8345 - val_acc: 0.7111\n",
      "Epoch 59/92\n",
      "546/546 [==============================] - 84s 154ms/step - loss: 0.1799 - acc: 0.9359 - val_loss: 0.8443 - val_acc: 0.7056\n",
      "Epoch 60/92\n",
      "546/546 [==============================] - 83s 153ms/step - loss: 0.1745 - acc: 0.9396 - val_loss: 0.8552 - val_acc: 0.7000\n",
      "Epoch 61/92\n",
      "546/546 [==============================] - 80s 147ms/step - loss: 0.1691 - acc: 0.9432 - val_loss: 0.8657 - val_acc: 0.7000\n",
      "Epoch 62/92\n",
      "546/546 [==============================] - 81s 148ms/step - loss: 0.1637 - acc: 0.9432 - val_loss: 0.8771 - val_acc: 0.7000\n",
      "Epoch 63/92\n",
      "546/546 [==============================] - 87s 160ms/step - loss: 0.1584 - acc: 0.9432 - val_loss: 0.8910 - val_acc: 0.7000\n",
      "Epoch 64/92\n",
      "546/546 [==============================] - 84s 154ms/step - loss: 0.1531 - acc: 0.9451 - val_loss: 0.9033 - val_acc: 0.7000\n",
      "Epoch 65/92\n",
      "546/546 [==============================] - 86s 158ms/step - loss: 0.1479 - acc: 0.9469 - val_loss: 0.9151 - val_acc: 0.7111\n",
      "Epoch 66/92\n",
      "546/546 [==============================] - 91s 166ms/step - loss: 0.1428 - acc: 0.9505 - val_loss: 0.9278 - val_acc: 0.7111\n",
      "Epoch 67/92\n",
      "546/546 [==============================] - 92s 169ms/step - loss: 0.1377 - acc: 0.9560 - val_loss: 0.9396 - val_acc: 0.7111\n",
      "Epoch 68/92\n",
      "546/546 [==============================] - 92s 169ms/step - loss: 0.1326 - acc: 0.9560 - val_loss: 0.9529 - val_acc: 0.7111\n",
      "Epoch 69/92\n",
      "546/546 [==============================] - 84s 154ms/step - loss: 0.1277 - acc: 0.9560 - val_loss: 0.9674 - val_acc: 0.7222\n",
      "Epoch 70/92\n",
      "546/546 [==============================] - 80s 146ms/step - loss: 0.1228 - acc: 0.9597 - val_loss: 0.9818 - val_acc: 0.7222\n",
      "Epoch 71/92\n",
      "546/546 [==============================] - 86s 157ms/step - loss: 0.1180 - acc: 0.9597 - val_loss: 0.9978 - val_acc: 0.7222\n",
      "Epoch 72/92\n",
      "546/546 [==============================] - 83s 153ms/step - loss: 0.1133 - acc: 0.9597 - val_loss: 1.0123 - val_acc: 0.7222\n",
      "Epoch 73/92\n",
      "546/546 [==============================] - 87s 159ms/step - loss: 0.1087 - acc: 0.9634 - val_loss: 1.0289 - val_acc: 0.7222\n",
      "Epoch 74/92\n",
      "546/546 [==============================] - 90s 165ms/step - loss: 0.1041 - acc: 0.9689 - val_loss: 1.0445 - val_acc: 0.7222\n",
      "Epoch 75/92\n",
      "546/546 [==============================] - 91s 167ms/step - loss: 0.0997 - acc: 0.9725 - val_loss: 1.0630 - val_acc: 0.7222\n",
      "Epoch 76/92\n",
      "546/546 [==============================] - 83s 152ms/step - loss: 0.0954 - acc: 0.9762 - val_loss: 1.0792 - val_acc: 0.7222\n",
      "Epoch 77/92\n",
      "546/546 [==============================] - 87s 160ms/step - loss: 0.0912 - acc: 0.9780 - val_loss: 1.0980 - val_acc: 0.7111\n",
      "Epoch 78/92\n",
      "546/546 [==============================] - 98s 179ms/step - loss: 0.0871 - acc: 0.9817 - val_loss: 1.1131 - val_acc: 0.7111\n",
      "Epoch 79/92\n",
      "546/546 [==============================] - 83s 153ms/step - loss: 0.0832 - acc: 0.9890 - val_loss: 1.1354 - val_acc: 0.7111\n",
      "Epoch 80/92\n",
      "546/546 [==============================] - 84s 154ms/step - loss: 0.0794 - acc: 0.9872 - val_loss: 1.1480 - val_acc: 0.7111\n",
      "Epoch 81/92\n",
      "546/546 [==============================] - 88s 162ms/step - loss: 0.0758 - acc: 0.9890 - val_loss: 1.1786 - val_acc: 0.7000\n",
      "Epoch 82/92\n",
      "546/546 [==============================] - 86s 158ms/step - loss: 0.0725 - acc: 0.9872 - val_loss: 1.1802 - val_acc: 0.7000\n",
      "Epoch 83/92\n",
      "546/546 [==============================] - 90s 164ms/step - loss: 0.0696 - acc: 0.9927 - val_loss: 1.2202 - val_acc: 0.7000\n",
      "Epoch 84/92\n",
      "546/546 [==============================] - 88s 161ms/step - loss: 0.0668 - acc: 0.9890 - val_loss: 1.2181 - val_acc: 0.7000\n",
      "Epoch 85/92\n",
      "546/546 [==============================] - 84s 154ms/step - loss: 0.0631 - acc: 0.9927 - val_loss: 1.2446 - val_acc: 0.6944\n",
      "Epoch 86/92\n",
      "546/546 [==============================] - 90s 165ms/step - loss: 0.0596 - acc: 0.9908 - val_loss: 1.2690 - val_acc: 0.6944\n",
      "Epoch 87/92\n",
      "546/546 [==============================] - 87s 159ms/step - loss: 0.0572 - acc: 0.9908 - val_loss: 1.2730 - val_acc: 0.7000\n",
      "Epoch 88/92\n",
      "546/546 [==============================] - 89s 162ms/step - loss: 0.0549 - acc: 0.9927 - val_loss: 1.3040 - val_acc: 0.6944\n",
      "Epoch 89/92\n",
      "546/546 [==============================] - 88s 161ms/step - loss: 0.0520 - acc: 0.9945 - val_loss: 1.3178 - val_acc: 0.6944\n",
      "Epoch 90/92\n",
      "546/546 [==============================] - 82s 150ms/step - loss: 0.0494 - acc: 0.9945 - val_loss: 1.3279 - val_acc: 0.7000\n",
      "Epoch 91/92\n",
      "546/546 [==============================] - 90s 165ms/step - loss: 0.0474 - acc: 0.9963 - val_loss: 1.3576 - val_acc: 0.6944\n",
      "Epoch 92/92\n",
      "546/546 [==============================] - 82s 151ms/step - loss: 0.0452 - acc: 0.9963 - val_loss: 1.3693 - val_acc: 0.6944\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_dim=8, init='uniform'))\n",
    "model.add(Dense(512, activation='relu',init='uniform'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(xtrain,ytrain, epochs=92, batch_size=10000, validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
